{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af940102",
   "metadata": {},
   "source": [
    "# 数据挖掘作业3\n",
    "## 姓名：胡宗晖 学号：3220220922\n",
    "### 基于支持向量机的手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fed506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d56ae",
   "metadata": {},
   "source": [
    "## 1.读取MNIST数据以及划分训练集与测试集\n",
    "### 1.1将MNIST数据集另存为png格式的图片，并按标签分别存放于0-9文件夹中\n",
    "#### 由于数据集网站已经将数据划分为训练集和测试集，以下将沿用这种划分方式，其中训练集样本60000个，测试集样本10000个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8fd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 预处理数据集\n",
    "\n",
    "# 将标签转换为字符串类型\n",
    "y_train = y_train.astype(str)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "# 创建一个文件夹，用于存储图片\n",
    "os.mkdir('D:/study/code/data/MNIST_png')\n",
    "os.mkdir('D:/study/code/data/MNIST_png/train')\n",
    "os.mkdir('D:/study/code/data/MNIST_png/test')\n",
    "\n",
    "# 创建10个文件夹，分别用0-9命名\n",
    "for i in range(10):\n",
    "    os.mkdir('D:/study/code/data/MNIST_png/train/'+str(i))\n",
    "    os.mkdir('D:/study/code/data/MNIST_png/test/'+str(i))\n",
    "\n",
    "# 遍历训练集，将每张图片以标签为文件名，保存为png格式 60000个\n",
    "for i in range(len(x_train)):\n",
    "    # 获取图片和标签\n",
    "    image = x_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    # 创建文件名，格式为\"label_index.png\"\n",
    "    filename = label + '_' + str(i) + '.png'\n",
    "\n",
    "    # 使用matplotlib库，将图片保存到指定文件夹\n",
    "    #plt.imsave(os.path.join('D:/study/code/data/MNIST_png/train', filename), image, cmap='gray')\n",
    "    plt.imsave('D:/study/code/data/MNIST_png/train/'+str(label) + \"/\" + str(label) + \"_\" + str(i) + \".png\",image, cmap=\"gray\")\n",
    "    \n",
    "# 遍历测试集，将每张图片以标签为文件名，保存为png格式 10000个\n",
    "for i in range(len(x_test)):\n",
    "    # 获取图片和标签\n",
    "    image = x_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    # 创建文件名，格式为\"label_index.png\"\n",
    "    filename = label + '_' + str(i) + '.png'\n",
    "\n",
    "    # 使用matplotlib库，将图片保存到指定文件夹\n",
    "    plt.imsave('D:/study/code/data/MNIST_png/test/'+str(label) + \"/\" + str(label) + \"_\" + str(i) + \".png\",image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a4321",
   "metadata": {},
   "source": [
    "## 2.读取数据并对图像数据进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f088d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取指定路径下的所有 .png 文件\n",
    "def get_file_list(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".png\")]\n",
    "\n",
    "\n",
    "# 解析出 .png 图件文件的名称\n",
    "def get_img_name_str(imgPath):\n",
    "    return imgPath.split(os.path.sep)[-1]\n",
    "# 将 20px * 20px 的图像数据转换成 1*400 的 numpy 向量\n",
    "# 参数：imgFile--图像名  如：0_1.png\n",
    "def img2vector(imgFile):\n",
    "    #print(\"in img2vector func--para:{}\".format(imgFile))\n",
    "    img = Image.open(imgFile).convert('L')\n",
    "    img_arr = np.array(img, 'i') # 20px * 20px 灰度图像\n",
    "    img_normalization = np.round(img_arr/255) # 对灰度值进行归一化\n",
    "    img_arr2 = np.reshape(img_normalization, (1,-1)) # 1 * 400 矩阵\n",
    "    return img_arr2\n",
    "    \n",
    "# 读取一个类别的所有数据并转换成矩阵 \n",
    "# 返回：某一类别的所有数据----[样本数量*(图像宽x图像高)] 矩阵\n",
    "def read_and_convert(imgFileList):\n",
    "    dataLabel = [] # 存放类标签\n",
    "    dataNum = len(imgFileList)\n",
    "    dataMat = np.zeros((dataNum, 784)) # dataNum * 400 的矩阵\n",
    "    for i in range(dataNum):\n",
    "        imgNameStr = imgFileList[i]\n",
    "        imgName = get_img_name_str(imgNameStr)  # 得到 数字_实例编号.png\n",
    "        #print(\"imgName: {}\".format(imgName))\n",
    "        classTag = imgName.split(\".\")[0].split(\"_\")[0] # 得到 类标签(数字)\n",
    "        #print(\"classTag: {}\".format(classTag))\n",
    "        dataLabel.append(classTag)\n",
    "        dataMat[i,:] = img2vector(imgNameStr)\n",
    "    return dataMat, dataLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c579030",
   "metadata": {},
   "source": [
    "### 2.1读取训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e279bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据\n",
    "def read_all_data():\n",
    "    cName = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    train_data_path = \"D:/study/code/data/MNIST_png/train/0\"\n",
    "    flist = get_file_list(train_data_path)\n",
    "    dataMat, dataLabel = read_and_convert(flist)\n",
    "    for c in cName:\n",
    "        train_data_path_ = \"D:/study/code/data/MNIST_png/train/\" + c\n",
    "        flist_ = get_file_list(train_data_path_)\n",
    "        dataMat_, dataLabel_ = read_and_convert(flist_)\n",
    "        dataMat = np.concatenate((dataMat, dataMat_), axis=0)\n",
    "        dataLabel = np.concatenate((dataLabel, dataLabel_), axis=0)\n",
    "    #print(dataMat.shape)\n",
    "    #print(len(dataLabel))\n",
    "    return dataMat, dataLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29108c5e",
   "metadata": {},
   "source": [
    "## 3.建立和训练SVM模型，核函数取rbf径向基核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f58661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training spent 181.9508s.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "def create_svm(dataMat, dataLabel, decision='ovr'):\n",
    "    clf = svm.SVC(decision_function_shape=decision,kernel='rbf')\n",
    "    clf.fit(dataMat, dataLabel)\n",
    "    return clf\n",
    "\n",
    "\n",
    "st = time.perf_counter()\n",
    "dataMat, dataLabel = read_all_data()\n",
    "clf = create_svm(dataMat, dataLabel, decision='ovr')\n",
    "et = time.perf_counter()\n",
    "print(\"Training spent {:.4f}s.\".format((et-st)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349f380",
   "metadata": {},
   "source": [
    "## 4.在测试集上进行预测，计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a621da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 has 1001 test cases\n",
      "errorCount: 3.\n",
      "*****************************\n",
      "class 1 has 1127 test cases\n",
      "errorCount: 5.\n",
      "*****************************\n",
      "class 2 has 991 test cases\n",
      "errorCount: 10.\n",
      "*****************************\n",
      "class 3 has 1032 test cases\n",
      "errorCount: 22.\n",
      "*****************************\n",
      "class 4 has 980 test cases\n",
      "errorCount: 6.\n",
      "*****************************\n",
      "class 5 has 863 test cases\n",
      "errorCount: 9.\n",
      "*****************************\n",
      "class 6 has 1014 test cases\n",
      "errorCount: 2.\n",
      "*****************************\n",
      "class 7 has 1070 test cases\n",
      "errorCount: 15.\n",
      "*****************************\n",
      "class 8 has 944 test cases\n",
      "errorCount: 12.\n",
      "*****************************\n",
      "class 9 has 978 test cases\n",
      "errorCount: 14.\n",
      "*****************************\n",
      "Testing All class total spent 161.293890s.\n",
      "sum of test cases: 10000\n",
      "All error Count is: 98.\n",
      "Average accuracy is: 0.990159.\n",
      "Average error rate is: 0.009841.\n"
     ]
    }
   ],
   "source": [
    "# 对10个数字进行分类测试\n",
    "tbasePath = \"D:/study/code/data/MNIST_png/test/\"\n",
    "tcName = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "tst = time.perf_counter()\n",
    "allErrCount = 0\n",
    "allErrorRate = 0.0\n",
    "allScore = 0.0\n",
    "allCount = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for tcn  in tcName:\n",
    "    testPath = \"D:/study/code/data/MNIST_png/test/\" + tcn\n",
    "    tflist = get_file_list(testPath)\n",
    "    tdataMat, tdataLabel = read_and_convert(tflist)\n",
    "    print(\"class \"+tcn+\" has {}\".format(len(tdataLabel))+\" test cases\")\n",
    "    allCount += len(tdataLabel)\n",
    "    pre_st = time.perf_counter()\n",
    "    preResult = clf.predict(tdataMat)\n",
    "    pre_et = time.perf_counter()\n",
    "    errCount = len([x for x in preResult if x!=tcn])\n",
    "    print(\"errorCount: {}.\".format(errCount))\n",
    "    print(\"*****************************\")\n",
    "    allErrCount += errCount\n",
    "    score_st = time.perf_counter()\n",
    "    score = clf.score(tdataMat, tdataLabel)\n",
    "    score_et = time.perf_counter()\n",
    "    allScore += score\n",
    "    #y_pred.append(preResult)\n",
    "    y_pred = y_pred + list(preResult)\n",
    "    \n",
    "    for i in range(len(tdataLabel)):\n",
    "        y_true.append(tcn)\n",
    "\n",
    "\n",
    "tet = time.perf_counter()\n",
    "print(\"Testing All class total spent {:.6f}s.\".format(tet-tst))\n",
    "print(\"sum of test cases: {}\".format(allCount))\n",
    "print(\"All error Count is: {}.\".format(allErrCount))\n",
    "avgAccuracy = allScore/10.0\n",
    "print(\"Average accuracy is: {:.6f}.\".format(avgAccuracy))\n",
    "print(\"Average error rate is: {:.6f}.\".format(1-avgAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee2ebb",
   "metadata": {},
   "source": [
    "## 计算召回率、F1值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd128c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成混淆矩阵：\n",
      "[[ 998    0    0    0    2    0    1    0    0    0]\n",
      " [   0 1122    1    0    1    0    0    0    1    2]\n",
      " [   0    3  981    1    1    1    0    1    2    1]\n",
      " [   0    1    2 1010    0    4    0    8    4    3]\n",
      " [   0    1    0    0  974    0    0    0    0    5]\n",
      " [   1    0    1    3    2  854    2    0    0    0]\n",
      " [   1    0    0    0    0    1 1012    0    0    0]\n",
      " [   0    2    3    0    5    0    0 1055    1    4]\n",
      " [   1    4    1    0    0    3    2    1  932    0]\n",
      " [   3    2    0    3    5    0    0    1    0  964]]\n",
      "每个类别的召回率：\n",
      "[0.997003   0.99556344 0.98990918 0.97868217 0.99387755 0.98957126\n",
      " 0.99802761 0.98598131 0.98728814 0.98568507]\n",
      "整体召回率：\n",
      "0.9901588736005473\n",
      "\n",
      "\n",
      "每个类别的f1值：\n",
      "[0.99551122 0.99204244 0.99090909 0.98584675 0.98883249 0.98957126\n",
      " 0.99655342 0.98782772 0.98938429 0.9851814 ]\n",
      "整体f1值：\n",
      "0.9901660084197468\n"
     ]
    }
   ],
   "source": [
    "# 生成混淆矩阵\n",
    "print(\"生成混淆矩阵：\")\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "# 计算每个类别的召回率\n",
    "print(\"每个类别的召回率：\")\n",
    "recall_per_class = metrics.recall_score(y_true, y_pred, average=None)\n",
    "print(recall_per_class)\n",
    "\n",
    "# 计算整体召回率（Macro-F1）\n",
    "print(\"整体召回率：\")\n",
    "recall_macro = metrics.recall_score(y_true, y_pred, average='macro')\n",
    "print(recall_macro)\n",
    "print('\\n')\n",
    "\n",
    "# 计算每个类别的f1值\n",
    "print(\"每个类别的f1值：\")\n",
    "f1_per_class = metrics.f1_score(y_true, y_pred, average=None)\n",
    "print(f1_per_class)\n",
    "\n",
    "# 计算整体f1值（Macro-F1）\n",
    "print(\"整体f1值：\")\n",
    "f1_macro = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "print(f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb78277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
